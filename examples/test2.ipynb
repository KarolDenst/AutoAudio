{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('../src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projects\\AutoAudio\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import preprocessing as pre\n",
    "import os\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import preprocessing as pre\n",
    "from models.transformer import AudioTransformer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"../data/\"\n",
    "file_paths = []\n",
    "labels = []\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        label = int(filename[0])\n",
    "        file_paths.append(file_path)\n",
    "        labels.append(str(label))\n",
    "\n",
    "data = pd.DataFrame({\"file_path\": file_paths, \"label\": labels})\n",
    "\n",
    "features = pre.aggregate_audio_features(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(drop=True, inplace=True)\n",
    "features, audios = pre.aggregate_audio_features(data)\n",
    "features.reset_index(drop=True, inplace=True)\n",
    "audios.reset_index(drop=True, inplace=True)\n",
    "\n",
    "labels = data[\"label\"]\n",
    "\n",
    "test_size = 0.2\n",
    "indices = labels.index\n",
    "train_indices, test_indices = train_test_split(\n",
    "    indices, test_size=test_size, random_state=42, shuffle=True\n",
    ")\n",
    "audios_train = audios.loc[train_indices]\n",
    "audios_test = audios.loc[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projects\\AutoAudio\\env\\Lib\\site-packages\\transformers\\configuration_utils.py:311: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "unique = np.unique(labels)\n",
    "n_unique = len(unique)\n",
    "\n",
    "label2id = {}\n",
    "id2label = {}\n",
    "for i, label in enumerate(unique):\n",
    "    label2id[label] = i\n",
    "    id2label[i] = label\n",
    "model = AudioTransformer(n_unique, label2id, id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function AudioTransformer.encode_dataset.<locals>.preprocess_function at 0x000002414C891E40> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "Map: 100%|██████████| 16/16 [00:00<00:00, 200.31 examples/s]\n",
      "Map: 100%|██████████| 4/4 [00:00<00:00, 250.65 examples/s]\n",
      "                                             \n",
      "100%|██████████| 1/1 [00:05<00:00,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0905935764312744, 'eval_accuracy': 0.25, 'eval_runtime': 0.4517, 'eval_samples_per_second': 8.855, 'eval_steps_per_second': 2.214, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:07<00:00,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 7.4327, 'train_samples_per_second': 2.153, 'train_steps_per_second': 0.135, 'train_loss': 1.096879482269287, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(audios_train, audios_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '1', '0', '1'], dtype='<U1')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(audios_test)\n",
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
